{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96ad4d3-d0b1-43f2-aa18-c449522a00f7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d33692-8f1f-4ee6-9331-e2ab907db4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d179cfe5-37c9-4f5b-8fa4-f56809fca525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 21:33:42.151899: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-26 21:33:42.204573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-26 21:33:42.204613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-26 21:33:42.206435: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-26 21:33:42.214101: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-26 21:33:42.215297: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 21:33:43.756681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tarfile\n",
    "import io\n",
    "import shutil\n",
    "from io import StringIO, BytesIO\n",
    "import joblib\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b666c9f-ee0f-4772-b57a-0ac26f32f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: code_sku/.ipynb_checkpoints/preprocess-checkpoint.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/.ipynb_checkpoints/preprocess-checkpoint.py\n",
      "upload: code_sku/requirements.txt to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/requirements.txt\n",
      "upload: code_sku/__pycache__/preprocess.cpython-310.pyc to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/__pycache__/preprocess.cpython-310.pyc\n",
      "upload: code_sku/util.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/util.py\n",
      "upload: code_sku/preprocess.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/preprocess.py\n",
      "upload: code_sku/inference.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/inference.py\n",
      "upload: code_sku/.ipynb_checkpoints/inference-checkpoint.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku/.ipynb_checkpoints/inference-checkpoint.py\n",
      "upload: code_sku1/requirements.txt to s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/requirements.txt\n",
      "upload: code_sku1/.ipynb_checkpoints/preprocess-checkpoint.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/.ipynb_checkpoints/preprocess-checkpoint.py\n",
      "upload: code_sku1/inference.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/inference.py\n",
      "upload: code_sku1/util.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/util.py\n",
      "upload: code_sku1/preprocess.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/preprocess.py\n",
      "upload: code_sku1/.ipynb_checkpoints/inference-checkpoint.py to s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/.ipynb_checkpoints/inference-checkpoint.py\n"
     ]
    }
   ],
   "source": [
    "# upload latest inference code & dependencies to s3 - RUN WHEN INFERENCE FILES CHANGED\n",
    "# !aws s3 cp --recursive inference/ s3://arbit-algo/sagemaker/algo-v1/input/inference/\n",
    "# !aws s3 cp --recursive code_sku/ s3://arbit-algo/sagemaker/algo-v1/input/code_sku/\n",
    "# !aws s3 cp --recursive code1/ s3://arbit-algo/sagemaker/algo-v1/input/code1/\n",
    "# !aws s3 cp --recursive code_sku1/ s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "377261ce-725a-4348-acfb-d6235d6565e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define IAM role\n",
    "# role = get_execution_role()\n",
    "# my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "# aws_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "# print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8abe44-25c9-4474-8acb-4c8cd34aa19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# needed functions\n",
    "\n",
    "def regression_scores(y_test, preds, transformed=False):\n",
    "    '''\n",
    "    Returns and prints evaluation metics for a regression model\n",
    "    '''\n",
    "    if transformed:\n",
    "\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse =  mean_squared_error(y_test, preds, squared=False)\n",
    "        rmse_exp = mean_squared_error(np.exp(y_test), np.exp(preds), squared=False)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mae_exp = mean_absolute_error(np.exp(y_test), np.exp(preds))\n",
    "\n",
    "    else:\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse =  mean_squared_error(y_test, preds, squared=False)\n",
    "        rmse_exp = 'N/A'\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mae_exp = 'N/A'\n",
    "        \n",
    "    r2 = r2_score(y_test, preds)\n",
    "    adj_r2 = 'N/A'\n",
    "\n",
    "    print('MSE: ', mse)\n",
    "    print('RMSE: ', rmse)\n",
    "    print('RMSE (retuned to normal scale): ', rmse_exp)\n",
    "    print('MAE: ', mae)\n",
    "    print('MAE (retuned to normal scale): ', mae_exp)\n",
    "    print('R-squared: ', r2)\n",
    "\n",
    "    return mse, rmse, rmse_exp, mae, mae_exp, r2, adj_r2\n",
    "\n",
    "def score_table(scores, model_name, y_test, preds, transformed=False, notes=None):\n",
    "    '''\n",
    "    creates a data frame with various scores for each model\n",
    "    '''\n",
    "    \n",
    "    mse, rmse, rmse_exp, mae, mae_exp, r2, adj_r2 = regression_scores(y_test, preds, transformed)\n",
    "    \n",
    "    score_list = []\n",
    "    score_list.extend((mse, rmse, rmse_exp, mae, mae_exp, r2, adj_r2, notes))\n",
    "    \n",
    "    scores.loc[model_name] = score_list\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea9a7b31-9e6a-4b53-86ae-13545a8064c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/.ipynb_checkpoints/inference-checkpoint.py to code_sku/.ipynb_checkpoints/inference-checkpoint.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/requirements.txt to code_sku/requirements.txt\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/__pycache__/preprocess.cpython-310.pyc to code_sku/__pycache__/preprocess.cpython-310.pyc\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/.ipynb_checkpoints/preprocess-checkpoint.py to code_sku/.ipynb_checkpoints/preprocess-checkpoint.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/inference.py to code_sku/inference.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/util.py to code_sku/util.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku/preprocess.py to code_sku/preprocess.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/inference.py to code_sku1/inference.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/.ipynb_checkpoints/inference-checkpoint.py to code_sku1/.ipynb_checkpoints/inference-checkpoint.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/preprocess.py to code_sku1/preprocess.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/util.py to code_sku1/util.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/.ipynb_checkpoints/preprocess-checkpoint.py to code_sku1/.ipynb_checkpoints/preprocess-checkpoint.py\n",
      "download: s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/requirements.txt to code_sku1/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://arbit-algo/sagemaker/algo-v1/input/code_sku/ code_sku/\n",
    "!aws s3 cp --recursive s3://arbit-algo/sagemaker/algo-v1/input/code_sku1/ code_sku1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000692b0-5d02-405d-9e5d-04ffb61acf56",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403885a-985e-4d24-9ada-ed9e9ce7a524",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fa8e0b-b700-40af-a3e4-2f3c76016412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/keras_metadata.pb\n",
      "1/assets\n",
      "1/saved_model.pb\n",
      "1/variables\n",
      "1/variables/variables.data-00000-of-00001\n",
      "1/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "get_last_modified = lambda obj: int(obj['LastModified'].strftime('%s'))\n",
    "s3 = boto3.client('s3')\n",
    "objs = s3.list_objects_v2(Bucket='arbit-algo', Prefix='sagemaker/algo-v1/output/models/3/')['Contents']\n",
    "keys_with_model_tar_gz = [item for item in objs if 'model.tar.gz' in item['Key']]\n",
    "last_added = [obj['Key'] for obj in sorted(keys_with_model_tar_gz, key=get_last_modified, reverse=True)][0]\n",
    "\n",
    "if os.path.exists('1') and os.path.isdir('1'):\n",
    "    shutil.rmtree('1')\n",
    "\n",
    "s3_object = s3.get_object(Bucket='arbit-algo', Key=last_added)\n",
    "\n",
    "wholefile = s3_object['Body'].read()\n",
    "fileobj = io.BytesIO(wholefile)\n",
    "tarf = tarfile.open(fileobj=fileobj)\n",
    "names = tarf.getnames()\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "model_files = [names]\n",
    "tarf.extractall()\n",
    "\n",
    "model = tf.keras.models.load_model('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1a6f17-3858-428b-bd5c-b4590754cda6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code_sku/preprocess.py:90: DtypeWarning: Columns (9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunks in pd.read_csv(file_path, chunksize=100000, header=0):\n",
      "/root/historical-sales-analysis/code_sku/preprocess.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# just to make sure we capture all columns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_train_preprocessed3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3://arbit-algo/sagemaker/algo-v1/processing/output/train/X_train_sku.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 11\u001b[0m df_model \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_sku\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#from preprocess_v1\u001b[39;00m\n\u001b[1;32m     12\u001b[0m df_model \u001b[38;5;241m=\u001b[39m df_model[(df_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSOLD_PRICE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRETAILPRICE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_sales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     13\u001b[0m df_model \u001b[38;5;241m=\u001b[39m df_model\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/historical-sales-analysis/code_sku/preprocess.py:414\u001b[0m, in \u001b[0;36mfinal_sku\u001b[0;34m(data_filepath, inference)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinal_sku\u001b[39m(data_filepath, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    413\u001b[0m     min_sale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 414\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_cleanup_sku\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_sale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m#, oldest_sale=oldest_sale) #additional_history=df_2022, oldest_sale=oldest_sale)\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/historical-sales-analysis/code_sku/preprocess.py:384\u001b[0m, in \u001b[0;36mfinal_cleanup_sku\u001b[0;34m(data, min_sale, oldest_sale, inference)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinal_cleanup_sku\u001b[39m(data, min_sale, oldest_sale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''final cleaning - check data types, deal with missing values & return final dataframe'''\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     df_final \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_final_sku\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_sale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moldest_sale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moldest_sale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# lowercase\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m#df_final = string_cleanup(df_final)\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# subset columns\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# TODO: include name column for collabs\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     columns_fin \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSILHOUETTE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBRAND\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGENDER\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSOLD_AT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS_COLLAB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS_OG_SE\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m#'SOURCE', 'CONDITION', \u001b[39;00m\n\u001b[1;32m    392\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOLOR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRETAILPRICE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_SINCE_RELEASE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSOLD_PRICE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOWEST_ASK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#'DAYS_SINCE_ASK'\u001b[39;00m\n\u001b[1;32m    393\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSOLD_YEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELEASEYEAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELEASEDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_sales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary_source\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    394\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_sale_px\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_SINCE_LAST_SALE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#'avg_sale_px',\u001b[39;00m\n\u001b[1;32m    395\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAST_SALE_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/historical-sales-analysis/code_sku/preprocess.py:356\u001b[0m, in \u001b[0;36mpreprocess_final_sku\u001b[0;34m(data, min_sale, oldest_sale, inference)\u001b[0m\n\u001b[1;32m    354\u001b[0m     df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_SINCE_LAST_SALE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (date\u001b[38;5;241m.\u001b[39mtoday() \u001b[38;5;241m-\u001b[39m df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAST_SALE_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_SINCE_LAST_SALE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdf_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSOLD_AT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLAST_SALE_DATE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mdays\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# # calc days since last sale\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m#df_final['DAYS_SINCE_LAST_SALE'] = (df_final['SOLD_AT'].dt.date - df_final['LAST_SALE_DATE'].dt.date).dt.days #dt.date \u001b[39;00m\n\u001b[1;32m    360\u001b[0m df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_SINCE_LAST_SALE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_SINCE_LAST_SALE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:6204\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6198\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6199\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6201\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6202\u001b[0m ):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/accessors.py:608\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "## SKU\n",
    "from code_sku.preprocess import *\n",
    "\n",
    "# PROCESSING DATA\n",
    "model_data = 's3://arbit-algo/sagemaker/algo-v1/processing/input/inference_sku/input_sku.csv'\n",
    "training_data = 's3://arbit-algo/sagemaker/algo-v1/processing/input/input_sku_training.csv'\n",
    "\n",
    "# just to make sure we capture all columns\n",
    "X_train_preprocessed3 = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/processing/output/train/X_train_sku.csv').iloc[:, 1:]\n",
    "\n",
    "df_model = final_sku(training_data) #from preprocess_v1\n",
    "df_model = df_model[(df_model['SOLD_PRICE'] > 5) & (df_model['RETAILPRICE']>5) & (df_model['num_sales']>=1)]\n",
    "df_model = df_model.dropna().reset_index(drop=True)\n",
    "\n",
    "X, y = final_preprocess_sku(df_model)\n",
    "#product_info_agg = X.to_csv('product_info.csv', index=True)\n",
    "\n",
    "# TODO: decide - should I do this on train data only??\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=10)\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', 'LOWEST_ASK', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0', 'lag1', 'lag2', 'lag3', 'lag4']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "# TODO: for batch don't need to load in chunks - can edit this in preprocess file\n",
    "df_new = final_sku(model_data, inference=True)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna().reset_index(drop=True) # drop any final missing values\n",
    "df_new.set_index('SKU', inplace=True)\n",
    "\n",
    "X_new, y_new = final_preprocess_sku(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "#df_new.to_csv('s3://arbit-algo/sagemaker/algo-v1/processing/input/input_transformed.csv', index=False)\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "#X_new = scaler.transform(X_new)\n",
    "\n",
    "# prefix = \"contains_\"\n",
    "# X_new_preprocessed = X_new_preprocessed.join(X_new.filter(regex=f'^{prefix}'))\n",
    "\n",
    "# Get missing columns inthe training test\n",
    "missing_cols = set(X_train_preprocessed3.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "X_new_preprocessed = X_new_preprocessed[X_train_preprocessed3.columns]\n",
    "#X_new_preprocessed = X_new_preprocessed.iloc[:,1:]\n",
    "\n",
    "# uncomment if needed\n",
    "#X_new_preprocessed.to_csv('X_inference_sku.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11a4a225-4a72-4212-818d-64caa3f632d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Preds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-b1a87433c415>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['std_sale_px'][df_merge.std_sale_px==0] = df_merge.predictions * mean_std_pct_non_zero\n",
      "<ipython-input-43-b1a87433c415>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['std_sale_px'][(df_merge.std_sale_px / df_merge.predictions < mean_std_pct_non_zero) & (df_merge.num_sales < 10)] = \\\n",
      "<ipython-input-43-b1a87433c415>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['prediction_low'] = df_final['predictions'] - mae_individual\n",
      "<ipython-input-43-b1a87433c415>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['prediction_high'] = df_final['predictions'] + mae_individual\n",
      "<ipython-input-43-b1a87433c415>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['SKU'] = df_final['SKU'].str.upper()\n",
      "<ipython-input-43-b1a87433c415>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['pred_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RELEASEDATE</th>\n",
       "      <th>predictions</th>\n",
       "      <th>prediction_low</th>\n",
       "      <th>prediction_high</th>\n",
       "      <th>pred_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>019000</td>\n",
       "      <td>men</td>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>81.398308</td>\n",
       "      <td>66.372344</td>\n",
       "      <td>96.424271</td>\n",
       "      <td>2023-12-21 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>019099</td>\n",
       "      <td>men</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>70.387589</td>\n",
       "      <td>64.975297</td>\n",
       "      <td>75.799880</td>\n",
       "      <td>2023-12-21 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>034563</td>\n",
       "      <td>men</td>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>93.974236</td>\n",
       "      <td>88.003323</td>\n",
       "      <td>99.945149</td>\n",
       "      <td>2023-12-21 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>036516</td>\n",
       "      <td>child</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>69.727715</td>\n",
       "      <td>62.441082</td>\n",
       "      <td>77.014347</td>\n",
       "      <td>2023-12-21 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000317</td>\n",
       "      <td>men</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>71.493988</td>\n",
       "      <td>62.879719</td>\n",
       "      <td>80.108257</td>\n",
       "      <td>2023-12-21 21:47:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SKU GENDER RELEASEDATE  predictions  prediction_low  prediction_high  \\\n",
       "0     019000    men  2020-12-08    81.398308       66.372344        96.424271   \n",
       "1     019099    men  2020-06-29    70.387589       64.975297        75.799880   \n",
       "2     034563    men  2014-09-16    93.974236       88.003323        99.945149   \n",
       "3     036516  child  2016-05-12    69.727715       62.441082        77.014347   \n",
       "4  100000317    men  2021-02-12    71.493988       62.879719        80.108257   \n",
       "\n",
       "             pred_date  \n",
       "0  2023-12-21 21:47:20  \n",
       "1  2023-12-21 21:47:20  \n",
       "2  2023-12-21 21:47:20  \n",
       "3  2023-12-21 21:47:20  \n",
       "4  2023-12-21 21:47:20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(X_new_preprocessed)\n",
    "df = pd.DataFrame(np.exp(preds), columns=['predictions'])\n",
    "\n",
    "product_info = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/output/product_info_sku.csv') # this needs to be non standardized\n",
    "# product_info = pd.read_csv('input_transformed.csv').reset_index(drop=True)\n",
    "# product_info = product_info.merge(size_map, on=['SKU', 'SIZE', 'GENDER'], how='left')\n",
    "\n",
    "df_merge = pd.concat([df, product_info], axis=1)\n",
    "\n",
    "mean_std_pct_non_zero = np.mean(df_merge['std_sale_px'][df_merge.std_sale_px>0] / df_merge['predictions'][df_merge.std_sale_px>0])\n",
    "\n",
    "# if std deviation is 0, replace with mean of std dev as pct of prediction value for all non zero std dev\n",
    "df_merge['std_sale_px'][df_merge.std_sale_px==0] = df_merge.predictions * mean_std_pct_non_zero\n",
    "\n",
    "# if less than 5 sales and std dev as % of pred is less than mean, replace with mean\n",
    "df_merge['std_sale_px'][(df_merge.std_sale_px / df_merge.predictions < mean_std_pct_non_zero) & (df_merge.num_sales < 10)] = \\\n",
    "    df_merge.predictions * mean_std_pct_non_zero\n",
    "\n",
    "# using model_training errors\n",
    "model_info = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/output/evaluation.csv')\n",
    "mae = model_info['mae_exp'][(~model_info.notes.isna()) & (model_info['notes'].str.contains('Model 3'))].iloc[-1]\n",
    "# mae_individual = mae * (df_merge.predictions / np.mean(df_merge.predictions))\n",
    "mae_individual = mae * (df_merge.std_sale_px / np.mean(df_merge.std_sale_px)) # using sneaker's standard deviation of price\n",
    "\n",
    "# need to get original unchanged size\n",
    "df_final = df_merge[['SKU', 'GENDER', 'RELEASEDATE', 'predictions']] #'GENDER',\n",
    "                     #'num_sales', 'DAYS_SINCE_LAST_SALE', 'DAYS_SINCE_RELEASE', 'std_sale_px', 'avg_sale_px_last_5', 'lag1', 'lag2', 'lag3']] # #'avg_sale_px', \n",
    "df_final['prediction_low'] = df_final['predictions'] - mae_individual\n",
    "df_final['prediction_low'] = df_final['prediction_low'].apply(lambda x: max(0, x))\n",
    "\n",
    "df_final['prediction_high'] = df_final['predictions'] + mae_individual\n",
    "df_final['SKU'] = df_final['SKU'].str.upper()\n",
    "\n",
    "df_final['predictions'] = df_final['predictions'].apply(lambda x: \"%.2f\" % x)\n",
    "df_final['prediction_low'] = df_final['prediction_low'].apply(lambda x: \"%.2f\" % x)\n",
    "df_final['prediction_high'] = df_final['prediction_high'].apply(lambda x: \"%.2f\" % x)\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "df_final['pred_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#df_final['pred_date'] = '2023-10-22'\n",
    "\n",
    "# save today's prediction - UNCOMMENT\n",
    "#df_final.to_csv('preds-9-26.csv')\n",
    "#df_final.to_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions/dt-{date.today()}/predictions.csv')\n",
    "\n",
    "# save historical prediction TODO: change mode to 'a'\n",
    "#output_path = 's3://arbit-algo/sagemaker/algo-v1/output/pred_history.csv'\n",
    "#df_final.to_csv(output_path, mode='a', header=False, index=False) #not os.path.exists(output_path))\n",
    "\n",
    "df_final.to_csv(f's3://justin-automation-output/outputs/output/predictions-sku/dt-{date.today()}/predictions_sku.csv')\n",
    "#df_final.to_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-sku/dt-2023-10-22/predictions_sku.csv')\n",
    "\n",
    "print('Model 3 Preds:')\n",
    "display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6daa42-4e67-443b-97aa-02efeef51420",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67a24529-087d-41dc-9476-2a6fd17da5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/saved_model.pb\n",
      "1/variables\n",
      "1/variables/variables.index\n",
      "1/variables/variables.data-00000-of-00001\n",
      "1/assets\n",
      "1/keras_metadata.pb\n"
     ]
    }
   ],
   "source": [
    "get_last_modified = lambda obj: int(obj['LastModified'].strftime('%s'))\n",
    "s3 = boto3.client('s3')\n",
    "objs = s3.list_objects_v2(Bucket='arbit-algo', Prefix='sagemaker/algo-v1/output/models/4/')['Contents']\n",
    "keys_with_model_tar_gz = [item for item in objs if 'model.tar.gz' in item['Key']]\n",
    "last_added = [obj['Key'] for obj in sorted(keys_with_model_tar_gz, key=get_last_modified, reverse=True)][0]\n",
    "\n",
    "if os.path.exists('1') and os.path.isdir('1'):\n",
    "    shutil.rmtree('1')\n",
    "\n",
    "s3_object = s3.get_object(Bucket='arbit-algo', Key=last_added)\n",
    "\n",
    "wholefile = s3_object['Body'].read()\n",
    "fileobj = io.BytesIO(wholefile)\n",
    "tarf = tarfile.open(fileobj=fileobj)\n",
    "names = tarf.getnames()\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "model_files = [names]\n",
    "tarf.extractall()\n",
    "\n",
    "model = tf.keras.models.load_model('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e2e1962-e17b-432b-a71f-5ddb48e02214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code_sku1/preprocess.py:404: DtypeWarning: Columns (9,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  data = final_cleanup_sku(data_filepath, min_sale, inference=inference)\n",
      "/root/historical-sales-analysis/code_sku1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n",
      "/root/historical-sales-analysis/code_sku1/preprocess.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hist_sales['RN'] = hist_sales['RN'] - 1 ## NEW\n",
      "/root/historical-sales-analysis/code_sku1/preprocess.py:404: DtypeWarning: Columns (9,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  data = final_cleanup_sku(data_filepath, min_sale, inference=inference)\n",
      "/root/historical-sales-analysis/code_sku1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 11148\n",
      "length of df_new: 11148\n",
      "lengths match? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETAILPRICE</th>\n",
       "      <th>DAYS_SINCE_RELEASE</th>\n",
       "      <th>source_count</th>\n",
       "      <th>num_sales</th>\n",
       "      <th>std_sale_px</th>\n",
       "      <th>DAYS_SINCE_LAST_SALE</th>\n",
       "      <th>lag0</th>\n",
       "      <th>LOWEST_ASK</th>\n",
       "      <th>GENDER_child</th>\n",
       "      <th>GENDER_infant</th>\n",
       "      <th>...</th>\n",
       "      <th>BRAND_saucony</th>\n",
       "      <th>BRAND_under armour</th>\n",
       "      <th>BRAND_vans</th>\n",
       "      <th>BRAND_veja</th>\n",
       "      <th>primary_source_alias</th>\n",
       "      <th>primary_source_ebay</th>\n",
       "      <th>primary_source_grailed</th>\n",
       "      <th>primary_source_stockx</th>\n",
       "      <th>IS_COLLAB_true</th>\n",
       "      <th>IS_OG_SE_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKU</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>019000</th>\n",
       "      <td>-1.392345</td>\n",
       "      <td>1.432047</td>\n",
       "      <td>2.082944</td>\n",
       "      <td>1.301146</td>\n",
       "      <td>-0.270047</td>\n",
       "      <td>-0.459698</td>\n",
       "      <td>-0.684657</td>\n",
       "      <td>0.695041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019099</th>\n",
       "      <td>-0.915112</td>\n",
       "      <td>1.849686</td>\n",
       "      <td>-0.430751</td>\n",
       "      <td>0.392275</td>\n",
       "      <td>-1.576516</td>\n",
       "      <td>5.462431</td>\n",
       "      <td>-1.288386</td>\n",
       "      <td>-0.602583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>034563</th>\n",
       "      <td>-0.915112</td>\n",
       "      <td>7.297045</td>\n",
       "      <td>-0.430751</td>\n",
       "      <td>0.392275</td>\n",
       "      <td>-1.450838</td>\n",
       "      <td>0.395720</td>\n",
       "      <td>-0.800659</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>036516</th>\n",
       "      <td>-1.976431</td>\n",
       "      <td>5.739920</td>\n",
       "      <td>-0.430751</td>\n",
       "      <td>0.128679</td>\n",
       "      <td>-1.196043</td>\n",
       "      <td>1.316940</td>\n",
       "      <td>-1.383288</td>\n",
       "      <td>-1.188048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000317</th>\n",
       "      <td>-0.915112</td>\n",
       "      <td>1.261897</td>\n",
       "      <td>-0.430751</td>\n",
       "      <td>-0.610374</td>\n",
       "      <td>-0.981889</td>\n",
       "      <td>0.461522</td>\n",
       "      <td>-1.699993</td>\n",
       "      <td>-0.386190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtntrck4</th>\n",
       "      <td>-1.572936</td>\n",
       "      <td>-0.210153</td>\n",
       "      <td>-1.687599</td>\n",
       "      <td>-1.297945</td>\n",
       "      <td>-1.561254</td>\n",
       "      <td>0.922132</td>\n",
       "      <td>-1.699993</td>\n",
       "      <td>-0.738479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtntrcn4</th>\n",
       "      <td>-1.572936</td>\n",
       "      <td>-0.210153</td>\n",
       "      <td>-1.687599</td>\n",
       "      <td>-0.986040</td>\n",
       "      <td>-1.096436</td>\n",
       "      <td>-0.196493</td>\n",
       "      <td>-1.517621</td>\n",
       "      <td>-0.084273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ww577vk</th>\n",
       "      <td>-1.064726</td>\n",
       "      <td>-0.772162</td>\n",
       "      <td>-1.687599</td>\n",
       "      <td>-0.628058</td>\n",
       "      <td>-1.604738</td>\n",
       "      <td>1.119536</td>\n",
       "      <td>-1.351128</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ww577vw</th>\n",
       "      <td>-1.064726</td>\n",
       "      <td>-0.772162</td>\n",
       "      <td>-1.687599</td>\n",
       "      <td>-0.467214</td>\n",
       "      <td>-2.962504</td>\n",
       "      <td>-0.328095</td>\n",
       "      <td>-1.535095</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wx452sg</th>\n",
       "      <td>-0.639327</td>\n",
       "      <td>0.491069</td>\n",
       "      <td>-0.430751</td>\n",
       "      <td>0.312280</td>\n",
       "      <td>-0.401175</td>\n",
       "      <td>1.777550</td>\n",
       "      <td>-0.554143</td>\n",
       "      <td>-1.030344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11148 rows  84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           RETAILPRICE  DAYS_SINCE_RELEASE  source_count  num_sales  \\\n",
       "SKU                                                                   \n",
       "019000       -1.392345            1.432047      2.082944   1.301146   \n",
       "019099       -0.915112            1.849686     -0.430751   0.392275   \n",
       "034563       -0.915112            7.297045     -0.430751   0.392275   \n",
       "036516       -1.976431            5.739920     -0.430751   0.128679   \n",
       "100000317    -0.915112            1.261897     -0.430751  -0.610374   \n",
       "...                ...                 ...           ...        ...   \n",
       "wtntrck4     -1.572936           -0.210153     -1.687599  -1.297945   \n",
       "wtntrcn4     -1.572936           -0.210153     -1.687599  -0.986040   \n",
       "ww577vk      -1.064726           -0.772162     -1.687599  -0.628058   \n",
       "ww577vw      -1.064726           -0.772162     -1.687599  -0.467214   \n",
       "wx452sg      -0.639327            0.491069     -0.430751   0.312280   \n",
       "\n",
       "           std_sale_px  DAYS_SINCE_LAST_SALE      lag0  LOWEST_ASK  \\\n",
       "SKU                                                                  \n",
       "019000       -0.270047             -0.459698 -0.684657    0.695041   \n",
       "019099       -1.576516              5.462431 -1.288386   -0.602583   \n",
       "034563       -1.450838              0.395720 -0.800659    0.483800   \n",
       "036516       -1.196043              1.316940 -1.383288   -1.188048   \n",
       "100000317    -0.981889              0.461522 -1.699993   -0.386190   \n",
       "...                ...                   ...       ...         ...   \n",
       "wtntrck4     -1.561254              0.922132 -1.699993   -0.738479   \n",
       "wtntrcn4     -1.096436             -0.196493 -1.517621   -0.084273   \n",
       "ww577vk      -1.604738              1.119536 -1.351128    0.077072   \n",
       "ww577vw      -2.962504             -0.328095 -1.535095    0.077072   \n",
       "wx452sg      -0.401175              1.777550 -0.554143   -1.030344   \n",
       "\n",
       "           GENDER_child  GENDER_infant  ...  BRAND_saucony  \\\n",
       "SKU                                     ...                  \n",
       "019000              0.0            0.0  ...            0.0   \n",
       "019099              0.0            0.0  ...            0.0   \n",
       "034563              0.0            0.0  ...            0.0   \n",
       "036516              1.0            0.0  ...            0.0   \n",
       "100000317           0.0            0.0  ...            0.0   \n",
       "...                 ...            ...  ...            ...   \n",
       "wtntrck4            0.0            0.0  ...            0.0   \n",
       "wtntrcn4            0.0            0.0  ...            0.0   \n",
       "ww577vk             0.0            0.0  ...            0.0   \n",
       "ww577vw             0.0            0.0  ...            0.0   \n",
       "wx452sg             0.0            0.0  ...            0.0   \n",
       "\n",
       "           BRAND_under armour  BRAND_vans  BRAND_veja  primary_source_alias  \\\n",
       "SKU                                                                           \n",
       "019000                    0.0         0.0         0.0                   1.0   \n",
       "019099                    0.0         0.0         0.0                   0.0   \n",
       "034563                    0.0         0.0         0.0                   1.0   \n",
       "036516                    0.0         0.0         0.0                   0.0   \n",
       "100000317                 0.0         0.0         0.0                   0.0   \n",
       "...                       ...         ...         ...                   ...   \n",
       "wtntrck4                  0.0         0.0         0.0                   0.0   \n",
       "wtntrcn4                  0.0         0.0         0.0                   0.0   \n",
       "ww577vk                   0.0         0.0         0.0                   0.0   \n",
       "ww577vw                   0.0         0.0         0.0                   0.0   \n",
       "wx452sg                   0.0         0.0         0.0                   0.0   \n",
       "\n",
       "           primary_source_ebay  primary_source_grailed  primary_source_stockx  \\\n",
       "SKU                                                                             \n",
       "019000                     0.0                     0.0                    0.0   \n",
       "019099                     1.0                     0.0                    0.0   \n",
       "034563                     0.0                     0.0                    0.0   \n",
       "036516                     0.0                     0.0                    1.0   \n",
       "100000317                  1.0                     0.0                    0.0   \n",
       "...                        ...                     ...                    ...   \n",
       "wtntrck4                   1.0                     0.0                    0.0   \n",
       "wtntrcn4                   1.0                     0.0                    0.0   \n",
       "ww577vk                    1.0                     0.0                    0.0   \n",
       "ww577vw                    1.0                     0.0                    0.0   \n",
       "wx452sg                    0.0                     0.0                    1.0   \n",
       "\n",
       "           IS_COLLAB_true  IS_OG_SE_true  \n",
       "SKU                                       \n",
       "019000                  0              0  \n",
       "019099                  0              0  \n",
       "034563                  0              0  \n",
       "036516                  0              0  \n",
       "100000317               0              0  \n",
       "...                   ...            ...  \n",
       "wtntrck4                0              0  \n",
       "wtntrcn4                0              0  \n",
       "ww577vk                 0              0  \n",
       "ww577vw                 0              0  \n",
       "wx452sg                 0              0  \n",
       "\n",
       "[11148 rows x 84 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from code_sku1.preprocess import *\n",
    "\n",
    "model_data = 's3://arbit-algo/sagemaker/algo-v1/processing/input/inference_sku/input_sku.csv'\n",
    "training_data = 's3://arbit-algo/sagemaker/algo-v1/processing/input/input_sku_training.csv'\n",
    "\n",
    "# just to make sure we capture all columns\n",
    "X_train_preprocessed4 = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/processing/output/train/X_train_sku2.csv')\n",
    "\n",
    "df_model = final_sku(training_data) #from preprocess_v1\n",
    "df_model = df_model[(df_model['SOLD_PRICE'] > 5) & (df_model['RETAILPRICE']>5) & (df_model['num_sales']>=1)]\n",
    "df_model = df_model.dropna().reset_index(drop=True)\n",
    "\n",
    "X, y = final_preprocess_sku(df_model)\n",
    "#product_info_agg = X.to_csv('product_info.csv', index=True)\n",
    "\n",
    "# TODO: decide - should I do this on train data only??\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=10)\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0', 'LOWEST_ASK']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "# TODO: for batch don't need to load in chunks - can edit this in preprocess file\n",
    "df_new = final_sku(model_data, inference=True)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna().reset_index(drop=True) # drop any final missing values\n",
    "df_new.set_index('SKU', inplace=True)\n",
    "\n",
    "X_new, y_new = final_preprocess_sku(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "#df_new.to_csv('s3://arbit-algo/sagemaker/algo-v1/processing/input/input_transformed.csv', index=False)\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "#X_new = scaler.transform(X_new)\n",
    "\n",
    "# prefix = \"contains_\"\n",
    "# X_new_preprocessed = X_new_preprocessed.join(X_new.filter(regex=f'^{prefix}'))\n",
    "\n",
    "\n",
    "# X_new_preprocessed_index = X_new_preprocessed.index\n",
    "\n",
    "# X_new_preprocessed = \\\n",
    "# X_new_preprocessed.reset_index(drop=True).join(X_new.reset_index(drop=True).filter(regex=f'^{prefix}'))\n",
    "\n",
    "# X_new_preprocessed.index = X_new_preprocessed_index\n",
    "\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed4.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "X_new_preprocessed = X_new_preprocessed[X_train_preprocessed4.columns]\n",
    "X_new_preprocessed = X_new_preprocessed.iloc[:,1:]\n",
    "\n",
    "X_new_preprocessed\n",
    "#X_new_preprocessed.to_csv('s3://arbit-algo/sagemaker/algo-v1/output/X_inference_sku2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32a10256-3d85-4b29-b00f-d5f26b208e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 Preds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-dfd46994fd55>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['std_sale_px'][df_merge.std_sale_px==0] = df_merge.predictions * mean_std_pct_non_zero\n",
      "<ipython-input-47-dfd46994fd55>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['std_sale_px'][(df_merge.std_sale_px / df_merge.predictions < mean_std_pct_non_zero) & (df_merge.num_sales < 5)] = \\\n",
      "<ipython-input-47-dfd46994fd55>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['prediction_low'] = df_final2['predictions'] - mae_individual\n",
      "<ipython-input-47-dfd46994fd55>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['prediction_high'] = df_final2['predictions'] + mae_individual\n",
      "<ipython-input-47-dfd46994fd55>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['SKU'] = df_final2['SKU'].str.upper()\n",
      "<ipython-input-47-dfd46994fd55>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['pred_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RELEASEDATE</th>\n",
       "      <th>predictions</th>\n",
       "      <th>prediction_low</th>\n",
       "      <th>prediction_high</th>\n",
       "      <th>pred_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>men</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>101.567223</td>\n",
       "      <td>53.366824</td>\n",
       "      <td>149.767621</td>\n",
       "      <td>2023-12-21 21:48:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011A824-026</td>\n",
       "      <td>men</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>73.168762</td>\n",
       "      <td>57.580430</td>\n",
       "      <td>88.757094</td>\n",
       "      <td>2023-12-21 21:48:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011A824-402</td>\n",
       "      <td>men</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>50.501717</td>\n",
       "      <td>44.950511</td>\n",
       "      <td>56.052922</td>\n",
       "      <td>2023-12-21 21:48:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011A826-021</td>\n",
       "      <td>men</td>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>53.291161</td>\n",
       "      <td>51.819175</td>\n",
       "      <td>54.763146</td>\n",
       "      <td>2023-12-21 21:48:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011A993-020</td>\n",
       "      <td>men</td>\n",
       "      <td>2021-08-21</td>\n",
       "      <td>53.503006</td>\n",
       "      <td>49.964793</td>\n",
       "      <td>57.041219</td>\n",
       "      <td>2023-12-21 21:48:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SKU GENDER RELEASEDATE  predictions  prediction_low  \\\n",
       "0           101    men  2021-04-26   101.567223       53.366824   \n",
       "1  1011A824-026    men  2021-10-07    73.168762       57.580430   \n",
       "2  1011A824-402    men  2022-03-10    50.501717       44.950511   \n",
       "3  1011A826-021    men  2022-06-03    53.291161       51.819175   \n",
       "4  1011A993-020    men  2021-08-21    53.503006       49.964793   \n",
       "\n",
       "   prediction_high            pred_date  \n",
       "0       149.767621  2023-12-21 21:48:04  \n",
       "1        88.757094  2023-12-21 21:48:04  \n",
       "2        56.052922  2023-12-21 21:48:04  \n",
       "3        54.763146  2023-12-21 21:48:04  \n",
       "4        57.041219  2023-12-21 21:48:04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(X_new_preprocessed)\n",
    "df = pd.DataFrame(np.exp(preds), columns=['predictions'])\n",
    "\n",
    "product_info = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/output/product_info_sku1.csv') # this needs to be non standardized\n",
    "# product_info = pd.read_csv('input_transformed.csv').reset_index(drop=True)\n",
    "# product_info = product_info.merge(size_map, on=['SKU', 'SIZE', 'GENDER'], how='left')\n",
    "\n",
    "df_merge = pd.concat([df, product_info], axis=1)\n",
    "\n",
    "## ASSIGNED EARLIER\n",
    "# mean_std_pct_non_zero = np.mean(df_merge['std_sale_px'][df_merge.std_sale_px>0] / df_merge['predictions'][df_merge.std_sale_px>0])\n",
    "\n",
    "# if std deviation is 0, replace with mean of std dev as pct of prediction value for all non zero std dev\n",
    "df_merge['std_sale_px'][df_merge.std_sale_px==0] = df_merge.predictions * mean_std_pct_non_zero\n",
    "\n",
    "# if less than 5 sales and std dev as % of pred is less than mean, replace with mean\n",
    "df_merge['std_sale_px'][(df_merge.std_sale_px / df_merge.predictions < mean_std_pct_non_zero) & (df_merge.num_sales < 5)] = \\\n",
    "    df_merge.predictions * mean_std_pct_non_zero\n",
    "\n",
    "# using model_training errors\n",
    "model_info = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/output/evaluation.csv')\n",
    "mae = model_info['mae_exp'][(~model_info.notes.isna()) & (model_info['notes'].str.contains('Model 4'))].iloc[-1]\n",
    "# mae_individual = mae * (df_merge.predictions / np.mean(df_merge.predictions))\n",
    "mae_individual = mae * (df_merge.std_sale_px / np.mean(df_merge.std_sale_px)) # using sneaker's standard deviation of price\n",
    "\n",
    "# need to get original unchanged size\n",
    "df_final2 = df_merge[['SKU', 'GENDER', 'RELEASEDATE', 'predictions']] #'GENDER',\n",
    "                     #'num_sales', 'DAYS_SINCE_LAST_SALE', 'DAYS_SINCE_RELEASE', 'std_sale_px', 'avg_sale_px_last_5', 'lag1', 'lag2', 'lag3']] # #'avg_sale_px', \n",
    "df_final2['prediction_low'] = df_final2['predictions'] - mae_individual\n",
    "df_final2['prediction_low'] = df_final2['prediction_low'].apply(lambda x: max(0, x))\n",
    "\n",
    "df_final2['prediction_high'] = df_final2['predictions'] + mae_individual\n",
    "df_final2['SKU'] = df_final2['SKU'].str.upper()\n",
    "\n",
    "# round to 2 decimals\n",
    "df_final2['predictions'] = df_final2['predictions'].apply(lambda x: \"%.2f\" % x)\n",
    "df_final2['prediction_low'] = df_final2['prediction_low'].apply(lambda x: \"%.2f\" % x)\n",
    "df_final2['prediction_high'] = df_final2['prediction_high'].apply(lambda x: \"%.2f\" % x)\n",
    "\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "df_final2['pred_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#df_final2['pred_date'] = '2023-10-22'\n",
    "\n",
    "#df_final = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-sku/dt-2023-10-22/predictions_sku.csv')\n",
    "\n",
    "df_final2 = df_final2[~df_final2.SKU.isin(list(set(df_final.SKU)))].reset_index(drop=True)\n",
    "\n",
    "df_final2.to_csv(f's3://justin-automation-output/outputs/output/predictions-sku/dt-{date.today()}/predictions_sku2.csv')\n",
    "#df_final2.to_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-sku/dt-2023-10-22/predictions_sku2.csv')\n",
    "\n",
    "print('Model 4 Preds:')\n",
    "display(df_final2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697381d-9f31-442f-8e8d-9e4df496efde",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f7007f9-b4a8-47f8-abbd-0225ea354aed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday's Predictions vs Yesterday's Actual Prices, SKU Model, Evaluation: \n",
      "MSE:  0.03483704005468016\n",
      "RMSE:  0.18664683242605581\n",
      "RMSE (retuned to normal scale):  37.17596294567497\n",
      "MAE:  0.13435643219091037\n",
      "MAE (retuned to normal scale):  20.911212927183374\n",
      "R-squared:  0.8522180669157295\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "scores = pd.DataFrame(columns = ['mse', 'rmse', 'rmse_exp', 'mae', 'mae_exp', 'r2', 'adj_r2', 'notes']) \n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "\n",
    "# preds for T-1\n",
    "preds1 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-sku/dt-{yesterday}/predictions_sku.csv')\n",
    "preds2 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-sku/dt-{yesterday}/predictions_sku2.csv')\n",
    "\n",
    "preds = pd.concat([preds1, preds2])\n",
    "# preds = pd.concat([df_final, df_final2])\n",
    "\n",
    "# ground truth\n",
    "# X_test = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/processing/output/test/X_test.csv')\n",
    "y_truth = pd.read_csv('s3://historicaldata-sample/ground_truth_sku.csv')\n",
    "\n",
    "# dropping missing values\n",
    "y_truth = y_truth.dropna()\n",
    "\n",
    "# subset where ground truth exists, log transform to get to scale of model\n",
    "final = pd.merge(y_truth[['SKU', 'RELEASEDATE', 'PRICE']], preds[['SKU', 'RELEASEDATE', 'predictions', 'prediction_low', 'prediction_high']], \n",
    "                 on=['SKU', 'RELEASEDATE'], how='inner')\n",
    "final['predictions'] = np.log(final.predictions)\n",
    "final['prediction_low'] = np.log(final.prediction_low)\n",
    "final['prediction_high'] = np.log(final.prediction_high)\n",
    "final['PRICE'] = np.log(final.PRICE)\n",
    "final['price_in_range'] = final.apply(lambda x: 1 if x['prediction_low'] <= x['PRICE'] <= x['prediction_high'] else 0, axis=1)\n",
    "final['eval_date'] = date.today()\n",
    "final = final.drop_duplicates().reset_index(drop=True)\n",
    "# final.to_csv('s3://arbit-algo/sagemaker/algo-v1/output/eval_values.csv', mode='a', header=False, index=False)\n",
    "\n",
    "# get and save scores\n",
    "model='AlgoV1'\n",
    "print(\"Yesterday's Predictions vs Yesterday's Actual Prices, SKU Model, Evaluation: \") \n",
    "score_table(scores, model, final['PRICE'], final['predictions'], transformed=True, \n",
    "            notes=f'Monitor SKU {str(date.today())}')\n",
    "eval_path = 's3://justin-automation-output/outputs/output/evaluation.csv'\n",
    "scores.reset_index().to_csv(eval_path, mode='a', header=False, index=False) #(not os.path.exists(eval_path)))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf-gpu-cuda8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7fe8e7156b155a9f3c09b83080291bb1bd38144b8399c123115114f3487f3b24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
