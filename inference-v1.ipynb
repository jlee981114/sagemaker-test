{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96ad4d3-d0b1-43f2-aa18-c449522a00f7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d179cfe5-37c9-4f5b-8fa4-f56809fca525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tarfile\n",
    "import io\n",
    "import shutil\n",
    "from io import StringIO, BytesIO\n",
    "import joblib\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c5ed0e-26d1-4bd0-9ff8-aa9769c5fb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = 'justin-automation-output'\n",
    "prefix = 'outputs'\n",
    "\n",
    "#s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8abe44-25c9-4474-8acb-4c8cd34aa19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# needed functions\n",
    "\n",
    "def regression_scores(y_test, preds, transformed=False):\n",
    "    '''\n",
    "    Returns and prints evaluation metics for a regression model\n",
    "    '''\n",
    "    if transformed:\n",
    "\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse =  mean_squared_error(y_test, preds, squared=False)\n",
    "        rmse_exp = mean_squared_error(np.exp(y_test), np.exp(preds), squared=False)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mae_exp = mean_absolute_error(np.exp(y_test), np.exp(preds))\n",
    "\n",
    "    else:\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse =  mean_squared_error(y_test, preds, squared=False)\n",
    "        rmse_exp = 'N/A'\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mae_exp = 'N/A'\n",
    "        \n",
    "    r2 = r2_score(y_test, preds)\n",
    "    adj_r2 = 'N/A'\n",
    "\n",
    "    print('MSE: ', mse)\n",
    "    print('RMSE: ', rmse)\n",
    "    print('RMSE (retuned to normal scale): ', rmse_exp)\n",
    "    print('MAE: ', mae)\n",
    "    print('MAE (retuned to normal scale): ', mae_exp)\n",
    "    print('R-squared: ', r2)\n",
    "\n",
    "    return mse, rmse, rmse_exp, mae, mae_exp, r2, adj_r2\n",
    "\n",
    "def score_table(scores, model_name, y_test, preds, transformed=False, notes=None):\n",
    "    '''\n",
    "    creates a data frame with various scores for each model\n",
    "    '''\n",
    "    \n",
    "    mse, rmse, rmse_exp, mae, mae_exp, r2, adj_r2 = regression_scores(y_test, preds, transformed)\n",
    "    \n",
    "    score_list = []\n",
    "    score_list.extend((mse, rmse, rmse_exp, mae, mae_exp, r2, adj_r2, notes))\n",
    "    \n",
    "    scores.loc[model_name] = score_list\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9a7b31-9e6a-4b53-86ae-13545a8064c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://arbit-algo/sagemaker/algo-v1/input/inference/ inference/\n",
    "!aws s3 cp --recursive s3://arbit-algo/sagemaker/algo-v1/input/code1/ code1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000692b0-5d02-405d-9e5d-04ffb61acf56",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403885a-985e-4d24-9ada-ed9e9ce7a524",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fa8e0b-b700-40af-a3e4-2f3c76016412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/keras_metadata.pb\n",
      "1/saved_model.pb\n",
      "1/assets\n",
      "1/variables\n",
      "1/variables/variables.data-00000-of-00001\n",
      "1/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "get_last_modified = lambda obj: int(obj['LastModified'].strftime('%s'))\n",
    "s3 = boto3.client('s3')\n",
    "objs = s3.list_objects_v2(Bucket='arbit-algo', Prefix='sagemaker/algo-v1/output/models/1/')['Contents']\n",
    "keys_with_model_tar_gz = [item for item in objs if 'model.tar.gz' in item['Key']]\n",
    "last_added = [obj['Key'] for obj in sorted(keys_with_model_tar_gz, key=get_last_modified, reverse=True)][0]\n",
    "\n",
    "if os.path.exists('1') and os.path.isdir('1'):\n",
    "    shutil.rmtree('1')\n",
    "\n",
    "s3_object = s3.get_object(Bucket='arbit-algo', Key=last_added)\n",
    "\n",
    "wholefile = s3_object['Body'].read()\n",
    "fileobj = io.BytesIO(wholefile)\n",
    "tarf = tarfile.open(fileobj=fileobj)\n",
    "names = tarf.getnames()\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "model_files = [names]\n",
    "tarf.extractall()\n",
    "\n",
    "model = tf.keras.models.load_model('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c08fe0f-dad0-44d8-afd3-65009506f6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/inference/preprocess.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    }
   ],
   "source": [
    "from inference.preprocess import *\n",
    "\n",
    "training_data = 's3://arbit-algo/sagemaker/algo-v1/processing/input/input_training.csv'\n",
    "\n",
    "# just to make sure we capture all columns\n",
    "X_train_preprocessed = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/processing/output/train/X_train.csv')\n",
    "\n",
    "df_model = final(training_data) #from preprocess_v1\n",
    "df_model = df_model[(df_model['SOLD_PRICE'] > 5) & \n",
    "                    (df_model['RETAILPRICE']>5) & \n",
    "                    (df_model['num_sales']>=20)]\n",
    "df_model = df_model.dropna().reset_index(drop=True)\n",
    "\n",
    "X, y = final_preprocess(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a8ad00-c825-4b6d-a2f5-70624de86d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/inference/preprocess.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 6785\n",
      "length of df_new: 6785\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 1\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0', 'lag1', 'lag2', 'lag3', 'lag4']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed1 = X_new_preprocessed[X_train_preprocessed.columns]\n",
    "\n",
    "#X_new_preprocessed.to_csv('X_inference1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0392fe8c-2789-45b0-9eb7-9d90bd59f488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/inference/preprocess.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 8552\n",
      "length of df_new: 8552\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 2\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0', 'lag1', 'lag2', 'lag3', 'lag4']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed2 = X_new_preprocessed[X_train_preprocessed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba79675d-5bcf-45c1-985f-48efaf951f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/inference/preprocess.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 1100\n",
      "length of df_new: 1100\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 3\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0', 'lag1', 'lag2', 'lag3', 'lag4']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed3 = X_new_preprocessed[X_train_preprocessed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b192a789-2cf1-4574-9f6e-fda1a38d2b00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/inference/preprocess.py:462: DtypeWarning: Columns (11,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  data = final_cleanup(data_filepath, min_sale, inference=inference)\n",
      "/root/historical-sales-analysis/inference/preprocess.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 26\n",
      "length of df_new: 26\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 4\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0', 'lag1', 'lag2', 'lag3', 'lag4']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed4 = X_new_preprocessed[X_train_preprocessed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "799d29b8-0749-4d26-ae3d-44b9bb25de9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Preds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-ab3a328613cc>:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['prediction_low'] = df_final['predictions'] - mae_individual\n",
      "<ipython-input-11-ab3a328613cc>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['prediction_high'] = df_final['predictions'] + mae_individual\n",
      "<ipython-input-11-ab3a328613cc>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['SKU'] = df_final['SKU'].str.upper()\n",
      "<ipython-input-11-ab3a328613cc>:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['ID'] = df_final['ID'].str.upper()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SKU</th>\n",
       "      <th>SIZE_VALUE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>predictions</th>\n",
       "      <th>prediction_low</th>\n",
       "      <th>prediction_high</th>\n",
       "      <th>pred_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201A019-108 10 2023-05-30</td>\n",
       "      <td>1201A019-108</td>\n",
       "      <td>269.0</td>\n",
       "      <td>men</td>\n",
       "      <td>214.782534</td>\n",
       "      <td>196.009124</td>\n",
       "      <td>233.555943</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1201A019-108 10.5 2023-05-30</td>\n",
       "      <td>1201A019-108</td>\n",
       "      <td>274.0</td>\n",
       "      <td>men</td>\n",
       "      <td>221.612510</td>\n",
       "      <td>211.317934</td>\n",
       "      <td>231.907086</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201A019-108 11 2023-05-30</td>\n",
       "      <td>1201A019-108</td>\n",
       "      <td>278.0</td>\n",
       "      <td>men</td>\n",
       "      <td>222.710947</td>\n",
       "      <td>198.570671</td>\n",
       "      <td>246.851223</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201A019-108 11.5 2023-05-30</td>\n",
       "      <td>1201A019-108</td>\n",
       "      <td>282.0</td>\n",
       "      <td>men</td>\n",
       "      <td>221.561792</td>\n",
       "      <td>205.914492</td>\n",
       "      <td>237.209093</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201A019-108 12 2023-05-30</td>\n",
       "      <td>1201A019-108</td>\n",
       "      <td>286.0</td>\n",
       "      <td>men</td>\n",
       "      <td>280.842367</td>\n",
       "      <td>239.875003</td>\n",
       "      <td>321.809732</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ID           SKU  SIZE_VALUE GENDER  predictions  \\\n",
       "0    1201A019-108 10 2023-05-30  1201A019-108       269.0    men   214.782534   \n",
       "1  1201A019-108 10.5 2023-05-30  1201A019-108       274.0    men   221.612510   \n",
       "2    1201A019-108 11 2023-05-30  1201A019-108       278.0    men   222.710947   \n",
       "3  1201A019-108 11.5 2023-05-30  1201A019-108       282.0    men   221.561792   \n",
       "4    1201A019-108 12 2023-05-30  1201A019-108       286.0    men   280.842367   \n",
       "\n",
       "   prediction_low  prediction_high   pred_date  \n",
       "0      196.009124       233.555943  2023-12-22  \n",
       "1      211.317934       231.907086  2023-12-22  \n",
       "2      198.570671       246.851223  2023-12-22  \n",
       "3      205.914492       237.209093  2023-12-22  \n",
       "4      239.875003       321.809732  2023-12-22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concatenating all preds\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed1)\n",
    "df1 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info1 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info_{len(df1)}.csv')\n",
    "product_info1 = product_info1.reset_index()\n",
    "\n",
    "df_merge1 = pd.concat([df1, product_info1], axis=1)\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed2)\n",
    "df2 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info2 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info_{len(df2)}.csv')\n",
    "product_info2 = product_info2.reset_index()\n",
    "\n",
    "df_merge2 = pd.concat([df2, product_info2], axis=1)\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed3)\n",
    "df3 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info3 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info_{len(df3)}.csv')\n",
    "product_info3 = product_info3.reset_index()\n",
    "\n",
    "df_merge3 = pd.concat([df3, product_info3], axis=1)\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed4)\n",
    "df4 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info4 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info_{len(df4)}.csv')\n",
    "product_info4 = product_info4.reset_index()\n",
    "\n",
    "df_merge4 = pd.concat([df4, product_info4], axis=1)\n",
    "\n",
    "# putting it all together\n",
    "df_merge = pd.concat([df_merge1, df_merge2[1:], df_merge3[1:], df_merge4[1:]], ignore_index=True)\n",
    "df_merge['predictions'] = [np.exp(float(x)) for x in df_merge['predictions']]\n",
    "\n",
    "model_info = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/output/evaluation.csv')\n",
    "mae = model_info['mae_exp'][(~model_info.notes.isna()) & (model_info['notes'].str.contains('Model 1'))].iloc[-1]\n",
    "# mae_individual = mae * (df_merge.predictions / np.mean(df_merge.predictions))\n",
    "mae_individual = mae * (df_merge.std_sale_px / np.mean(df_merge.std_sale_px)) # using sneaker's standard deviation of price\n",
    "\n",
    "# need to get original unchanged size\n",
    "df_final = df_merge[['ID', 'SKU', 'SIZE_CM', 'GENDER', 'predictions']]\n",
    "                     #'num_sales', 'DAYS_SINCE_LAST_SALE', 'DAYS_SINCE_RELEASE', 'std_sale_px', 'avg_sale_px_last_5', 'lag1', 'lag2', 'lag3']] # #'avg_sale_px', \n",
    "df_final['prediction_low'] = df_final['predictions'] - mae_individual\n",
    "df_final['prediction_low'] = df_final['prediction_low'].apply(lambda x: max(0, x))\n",
    "df_final['prediction_high'] = df_final['predictions'] + mae_individual\n",
    "df_final['SKU'] = df_final['SKU'].str.upper()\n",
    "df_final['ID'] = df_final['ID'].str.upper()\n",
    "df_final = df_final.rename(columns={'SIZE_CM': 'SIZE_VALUE'})\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "df_final['pred_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "df_final.to_csv(f's3://justin-automation-output/outputs/output/predictions-test/dt-{date.today()}/predictions1.csv')\n",
    "print('Model 1 Preds:')\n",
    "display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6daa42-4e67-443b-97aa-02efeef51420",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a24529-087d-41dc-9476-2a6fd17da5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/saved_model.pb\n",
      "1/variables\n",
      "1/variables/variables.index\n",
      "1/variables/variables.data-00000-of-00001\n",
      "1/assets\n",
      "1/keras_metadata.pb\n"
     ]
    }
   ],
   "source": [
    "get_last_modified = lambda obj: int(obj['LastModified'].strftime('%s'))\n",
    "s3 = boto3.client('s3')\n",
    "objs = s3.list_objects_v2(Bucket='arbit-algo', Prefix='sagemaker/algo-v1/output/models/2/')['Contents']\n",
    "keys_with_model_tar_gz = [item for item in objs if 'model.tar.gz' in item['Key']]\n",
    "last_added = [obj['Key'] for obj in sorted(keys_with_model_tar_gz, key=get_last_modified, reverse=True)][0]\n",
    "\n",
    "if os.path.exists('1') and os.path.isdir('1'):\n",
    "    shutil.rmtree('1')\n",
    "\n",
    "s3_object = s3.get_object(Bucket='arbit-algo', Key=last_added)\n",
    "\n",
    "wholefile = s3_object['Body'].read()\n",
    "fileobj = io.BytesIO(wholefile)\n",
    "tarf = tarfile.open(fileobj=fileobj)\n",
    "names = tarf.getnames()\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "model_files = [names]\n",
    "tarf.extractall()\n",
    "\n",
    "model = tf.keras.models.load_model('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94e7f6ef-61a2-4927-b143-130e372cb5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code1/preprocess.py:471: DtypeWarning: Columns (11,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  data = final_cleanup(data_filepath, min_sale, inference=inference, lag=lag)\n",
      "/root/historical-sales-analysis/code1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    }
   ],
   "source": [
    "from code1.preprocess import *\n",
    "\n",
    "training_data = 's3://arbit-algo/sagemaker/algo-v1/processing/input/input_training.csv'\n",
    "\n",
    "# just to make sure we capture all columns\n",
    "X_train_preprocessed = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/processing/output/train/X_train2.csv')\n",
    "\n",
    "df_model = final(training_data, lag=False) #from preprocess_v1\n",
    "df_model = df_model[(df_model['SOLD_PRICE'] > 5) & \n",
    "                    (df_model['RETAILPRICE']>5) & \n",
    "                    (df_model['num_sales']>=1)]\n",
    "df_model = df_model.dropna().reset_index(drop=True)\n",
    "\n",
    "X, y = final_preprocess(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9967150d-9931-4fd0-bfc0-0699aeb7c34c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 8392\n",
      "length of df_new: 8392\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 1\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True, lag=False)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed1 = X_new_preprocessed[X_train_preprocessed.columns]\n",
    "\n",
    "#X_new_preprocessed.to_csv('X_inference1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4572655f-5030-4127-b4b2-81ecb5652ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 19045\n",
      "length of df_new: 19045\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 2\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True, lag=False)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed2 = X_new_preprocessed[X_train_preprocessed.columns]\n",
    "\n",
    "#X_new_preprocessed.to_csv('X_inference1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddb921c6-c28d-4d21-b0f3-9b3ec34ebdc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 23179\n",
      "length of df_new: 23179\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "from code1.preprocess import *\n",
    "\n",
    "model_no = 3\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True, lag=False)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed3 = X_new_preprocessed[X_train_preprocessed.columns]\n",
    "\n",
    "#X_new_preprocessed.to_csv('X_inference1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c0ec56e-99fe-4633-8ea7-d968eecab963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/historical-sales-analysis/code1/preprocess.py:471: DtypeWarning: Columns (11,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  data = final_cleanup(data_filepath, min_sale, inference=inference, lag=lag)\n",
      "/root/historical-sales-analysis/code1/preprocess.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RELEASEDATE'][df.RELEASEDATE.isna()] = df['RELEASEDATE'][~df.RELEASEDATE.isna()].quantile(0.5, interpolation=\"midpoint\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_new: 40103\n",
      "length of df_new: 40103\n",
      "lengths match? True\n"
     ]
    }
   ],
   "source": [
    "model_no = 4\n",
    "\n",
    "model_data = f's3://arbit-algo/sagemaker/algo-v1/processing/input/inference/input_inference{model_no}.csv'\n",
    "\n",
    "bool_cols = ['IS_COLLAB', 'IS_OG_SE']\n",
    "cat = ['GENDER', 'SILHOUETTE', 'COLOR', 'BRAND', 'primary_source']\n",
    "cont = ['SIZE_CM', 'RETAILPRICE', 'num_sales', 'std_sale_px', 'DAYS_SINCE_LAST_SALE', #'avg_sale_px', \n",
    "        'DAYS_SINCE_RELEASE', 'source_count', 'lag0']\n",
    "\n",
    "scaler = StandardScaler().fit(X[cont]) # or X_train\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(X[cat])\n",
    "\n",
    "df_new = final(model_data, inference=True, lag=False)\n",
    "df_new = string_cleanup(df_new)\n",
    "df_new = df_new.dropna()#.reset_index(drop=True) # drop any final missing values\n",
    "\n",
    "X_new, y_new = final_preprocess(df_new)\n",
    "\n",
    "# drop any final missing & extreme values\n",
    "# deleting any infinity values (already scaled and logged, so this shouldnt be dropping any actual columns)\n",
    "\n",
    "print('length of X_new:', len(X_new))\n",
    "#X_new = X_new.reset_index(drop=True)\n",
    "mask = X_new.isna()\n",
    "X_new = X_new[~mask]#.reset_index(drop=True)\n",
    "\n",
    "# drop corresponing rows in model_data\n",
    "print('length of df_new:', len(df_new))\n",
    "\n",
    "df_new = df_new[~mask.any(axis=1)]#.reset_index(drop=True)\n",
    "print('lengths match?', len(X_new)==len(df_new))\n",
    "\n",
    "# one hot encode, scale & concat\n",
    "df_ohe_new = pd.DataFrame(ohe.transform(X_new[cat]).toarray(), \n",
    "                          columns=ohe.get_feature_names(X_new[cat].columns), \n",
    "                          index=X_new[cat].index)\n",
    "X_new_cont = pd.DataFrame(scaler.transform(X_new[cont]),columns=X_new[cont].columns,index=X_new[cont].index)\n",
    "bool_cols_new = pd.get_dummies(X_new[bool_cols], columns=bool_cols, drop_first= True)\n",
    "\n",
    "X_new_preprocessed = pd.concat([X_new_cont, df_ohe_new], axis=1)\n",
    "X_new_preprocessed = pd.concat([X_new_preprocessed, bool_cols_new], axis=1)\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set(X_train_preprocessed.columns) - set(X_new_preprocessed.columns)\n",
    "for c in missing_cols:\n",
    "    X_new_preprocessed[c] = 0\n",
    "\n",
    "X_new_preprocessed4 = X_new_preprocessed[X_train_preprocessed.columns]\n",
    "\n",
    "#X_new_preprocessed.to_csv('X_inference1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5f5d203-d9d3-416b-bd80-1a2fa28e3e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-fcee062390f1>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['std_sale_px'][df_merge.std_sale_px==0] = df_merge.predictions * mean_std_pct_non_zero\n",
      "<ipython-input-48-fcee062390f1>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['std_sale_px'][(df_merge.std_sale_px / df_merge.predictions < mean_std_pct_non_zero) & (df_merge.num_sales < 5)] = \\\n",
      "<ipython-input-48-fcee062390f1>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['prediction_low'] = df_final2['predictions'] - mae_individual\n",
      "<ipython-input-48-fcee062390f1>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['prediction_high'] = df_final2['predictions'] + mae_individual\n",
      "<ipython-input-48-fcee062390f1>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['SKU'] = df_final2['SKU'].str.upper()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Preds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-fcee062390f1>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['ID'] = df_final2['ID'].str.upper()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SKU</th>\n",
       "      <th>SIZE_VALUE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>predictions</th>\n",
       "      <th>prediction_low</th>\n",
       "      <th>prediction_high</th>\n",
       "      <th>pred_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201A019-108 14 2023-05-30</td>\n",
       "      <td>1201A019-108</td>\n",
       "      <td>303.0</td>\n",
       "      <td>men</td>\n",
       "      <td>287.873287</td>\n",
       "      <td>263.156358</td>\n",
       "      <td>312.590216</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1201A906-001 12.5 2023-05-31</td>\n",
       "      <td>1201A906-001</td>\n",
       "      <td>290.0</td>\n",
       "      <td>men</td>\n",
       "      <td>163.403779</td>\n",
       "      <td>135.911398</td>\n",
       "      <td>190.896159</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201A906-001 13 2023-05-31</td>\n",
       "      <td>1201A906-001</td>\n",
       "      <td>295.0</td>\n",
       "      <td>men</td>\n",
       "      <td>212.662906</td>\n",
       "      <td>157.396835</td>\n",
       "      <td>267.928977</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201A906-001 14 2023-05-31</td>\n",
       "      <td>1201A906-001</td>\n",
       "      <td>303.0</td>\n",
       "      <td>men</td>\n",
       "      <td>186.744538</td>\n",
       "      <td>149.535551</td>\n",
       "      <td>223.953524</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201A906-001 4 2023-05-31</td>\n",
       "      <td>1201A906-001</td>\n",
       "      <td>219.0</td>\n",
       "      <td>men</td>\n",
       "      <td>139.088985</td>\n",
       "      <td>124.344938</td>\n",
       "      <td>153.833032</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ID           SKU  SIZE_VALUE GENDER  predictions  \\\n",
       "0    1201A019-108 14 2023-05-30  1201A019-108       303.0    men   287.873287   \n",
       "1  1201A906-001 12.5 2023-05-31  1201A906-001       290.0    men   163.403779   \n",
       "2    1201A906-001 13 2023-05-31  1201A906-001       295.0    men   212.662906   \n",
       "3    1201A906-001 14 2023-05-31  1201A906-001       303.0    men   186.744538   \n",
       "4     1201A906-001 4 2023-05-31  1201A906-001       219.0    men   139.088985   \n",
       "\n",
       "   prediction_low  prediction_high   pred_date  \n",
       "0      263.156358       312.590216  2023-12-22  \n",
       "1      135.911398       190.896159  2023-12-22  \n",
       "2      157.396835       267.928977  2023-12-22  \n",
       "3      149.535551       223.953524  2023-12-22  \n",
       "4      124.344938       153.833032  2023-12-22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concatenating all preds\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed1)\n",
    "df1 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info1 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info2_{len(df1)}.csv')\n",
    "product_info1 = product_info1.reset_index()\n",
    "\n",
    "df_merge1 = pd.concat([df1, product_info1], axis=1)\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed2)\n",
    "df2 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info2 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info2_{len(df2)}.csv')\n",
    "product_info2 = product_info2.reset_index()\n",
    "\n",
    "df_merge2 = pd.concat([df2, product_info2], axis=1)\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed3)\n",
    "df3 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info3 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info2_{len(df3)}.csv')\n",
    "product_info3 = product_info3.reset_index()\n",
    "\n",
    "df_merge3 = pd.concat([df3, product_info3], axis=1)\n",
    "\n",
    "prediction = model.predict(X_new_preprocessed4)\n",
    "df4 = pd.DataFrame(prediction).rename(columns={0: 'predictions'})\n",
    "product_info4 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/processing/output/product_info2_{len(df4)}.csv')\n",
    "product_info4 = product_info4.reset_index()\n",
    "\n",
    "df_merge4 = pd.concat([df4, product_info4], axis=1)\n",
    "\n",
    "# putting it all together\n",
    "df_merge = pd.concat([df_merge1, df_merge2[1:], df_merge3[1:], df_merge4[1:]], ignore_index=True)\n",
    "df_merge['predictions'] = [round(np.exp(float(x)), 2) for x in df_merge['predictions']]\n",
    "\n",
    "mean_std_pct_non_zero = np.mean(df_merge['std_sale_px'][df_merge.std_sale_px>0] / df_merge['predictions'][df_merge.std_sale_px>0])\n",
    "\n",
    "# if std deviation is 0, replace with mean of std dev as pct of prediction value for all non zero std dev\n",
    "df_merge['std_sale_px'][df_merge.std_sale_px==0] = df_merge.predictions * mean_std_pct_non_zero\n",
    "\n",
    "# if less than 5 sales and std dev as % of pred is less than mean, replace with mean\n",
    "df_merge['std_sale_px'][(df_merge.std_sale_px / df_merge.predictions < mean_std_pct_non_zero) & (df_merge.num_sales < 5)] = \\\n",
    "    df_merge.predictions * mean_std_pct_non_zero\n",
    "\n",
    "model_info = pd.read_csv('s3://arbit-algo/sagemaker/algo-v1/output/evaluation.csv')\n",
    "mae = model_info['mae_exp'][(~model_info.notes.isna()) & (model_info['notes'].str.contains('Model 1'))].iloc[-1]\n",
    "# mae_individual = mae * (df_merge.predictions / np.mean(df_merge.predictions))\n",
    "mae_individual = mae * (df_merge.std_sale_px / np.mean(df_merge.std_sale_px)) # using sneaker's standard deviation of price\n",
    "\n",
    "# need to get original unchanged size\n",
    "df_final2 = df_merge[['ID', 'SKU', 'SIZE_CM', 'GENDER', 'predictions']]\n",
    "                     #'num_sales', 'DAYS_SINCE_LAST_SALE', 'DAYS_SINCE_RELEASE', 'std_sale_px', 'avg_sale_px_last_5', 'lag1', 'lag2', 'lag3']] # #'avg_sale_px', \n",
    "df_final2['prediction_low'] = df_final2['predictions'] - mae_individual\n",
    "df_final2['prediction_low'] = df_final2['prediction_low'].apply(lambda x: max(0, x))\n",
    "df_final2['prediction_high'] = df_final2['predictions'] + mae_individual\n",
    "\n",
    "# round to 2 decimals\n",
    "df_final2['predictions'] = df_final2['predictions'].apply(lambda x: \"%.2f\" % x)\n",
    "df_final2['prediction_low'] = df_final2['prediction_low'].apply(lambda x: \"%.2f\" % x)\n",
    "df_final2['prediction_high'] = df_final2['prediction_high'].apply(lambda x: \"%.2f\" % x)\n",
    "\n",
    "df_final2['SKU'] = df_final2['SKU'].str.upper()\n",
    "df_final2['ID'] = df_final2['ID'].str.upper()\n",
    "df_final2 = df_final2.rename(columns={'SIZE_CM': 'SIZE_VALUE'})\n",
    "\n",
    "df_final2 = df_final2[~df_final2.ID.isin(list(set(df_final.ID)))].reset_index(drop=True)\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "df_final2['pred_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "df_final2.to_csv(f's3://justin-automation-output/outputs/output/predictions-test/dt-{date.today()}/predictions2.csv')\n",
    "print('Model 2 Preds:')\n",
    "display(df_final2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697381d-9f31-442f-8e8d-9e4df496efde",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a3730-f53f-435b-a61d-e3503b2bd623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores = pd.DataFrame(columns = ['mse', 'rmse', 'rmse_exp', 'mae', 'mae_exp', 'r2', 'adj_r2', 'notes']) \n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "\n",
    "# preds for T-1\n",
    "preds1 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-test/dt-{yesterday}/predictions1.csv')\n",
    "preds2 = pd.read_csv(f's3://arbit-algo/sagemaker/algo-v1/output/predictions-test/dt-{yesterday}/predictions2.csv')\n",
    "preds = pd.concat([preds1, preds2])\n",
    "y_truth = pd.read_csv('s3://historicaldata-sample/ground_truth.csv')\n",
    "\n",
    "\n",
    "# dropping missing values\n",
    "y_truth = y_truth.dropna()\n",
    "\n",
    "\n",
    "y_truth['SIZE'] = y_truth['SIZE'].astype(str).apply(lambda x: x.rstrip('.0') if x.endswith('.0') else x)\n",
    "\n",
    "y_truth['ID'] = y_truth['SKU'].astype(str) + \" \" + y_truth['SIZE'].astype(str) + \" \" + y_truth['RELEASEDATE'].astype(str)\n",
    "y_truth['ID'] = y_truth['ID'].str.upper()\n",
    "\n",
    "# subset where ground truth exists, log transform to get to scale of model\n",
    "final = pd.merge(y_truth[['ID', 'PRICE']], preds[['ID', 'predictions', 'prediction_low', 'prediction_high']], on='ID', how='inner')\n",
    "final['predictions'] = np.log(final.predictions)\n",
    "final['prediction_low'] = np.log(final.prediction_low)\n",
    "final['prediction_high'] = np.log(final.prediction_high)\n",
    "final['PRICE'] = np.log(final.PRICE)\n",
    "final['price_in_range'] = final.apply(lambda x: 1 if x['prediction_low'] <= x['PRICE'] <= x['prediction_high'] else 0, axis=1)\n",
    "final['eval_date'] = date.today()\n",
    "\n",
    "final = final.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# get and save scores\n",
    "model='AlgoV1'\n",
    "print(\"Yesterday's Predictions vs Yesterday's Actual Prices, Sneaker Model, Evaluation: \") \n",
    "score_table(scores, model, final['PRICE'], final['predictions'], transformed=True, \n",
    "            notes=f'Monitor {str(date.today())}')\n",
    "\n",
    "eval_path = 's3://justin-automation-output/outputs/output/evaluation.csv'\n",
    "scores.reset_index().to_csv(eval_path, mode='a', header=False, index=False) #(not os.path.exists(eval_path)))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf-gpu-cuda8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7fe8e7156b155a9f3c09b83080291bb1bd38144b8399c123115114f3487f3b24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
